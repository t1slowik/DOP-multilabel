{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rozpoznawanie typów reklamacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, re, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ładowanie danych z pliku xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "datapath='/mnt/c/dev/DOP-categories/'\n",
    "datafile='Cases categorization.xlsx'\n",
    "dane_surowe=pd.read_excel(os.path.join(datapath,datafile))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dane_surowe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['casenumber', 'jira', 'contactemail', 'origin', 'status', '_type',\n",
       "       'record_name', 'record_desc', 'createddate', 'lastmodifieddate',\n",
       "       'closeddate', 'moneyrefund', 'owner_name', 'lastmod_name', 'case_desc',\n",
       "       'Unnamed: 15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dane_surowe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data=pd.DataFrame()\n",
    "input_data[['content','category']]=dane_surowe[['case_desc','Unnamed: 15']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>190</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>186</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Zawieszanie transmisji danych.</td>\n",
       "      <td>network; data transmission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               content                    category\n",
       "count                              190                         189\n",
       "unique                             186                         102\n",
       "top     Zawieszanie transmisji danych.  network; data transmission\n",
       "freq                                 4                          22"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Problem z wyświetlaniem informacji w FAQ -  w ...</td>\n",
       "      <td>FAQ; wrong copy;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W żadnej z kategorii nie ma sekcji 'najczęstsz...</td>\n",
       "      <td>FAQ; content categorization;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>moje konto&gt; mój plan &gt; szczegóły oferty aplika...</td>\n",
       "      <td>app crashes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Klient zgłsza problem z wyborem numerów. Przy ...</td>\n",
       "      <td>UX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Klienta nie może p.rzejść przez weryfikację nu...</td>\n",
       "      <td>OTP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  Problem z wyświetlaniem informacji w FAQ -  w ...   \n",
       "1  W żadnej z kategorii nie ma sekcji 'najczęstsz...   \n",
       "2  moje konto> mój plan > szczegóły oferty aplika...   \n",
       "3  Klient zgłsza problem z wyborem numerów. Przy ...   \n",
       "4  Klienta nie może p.rzejść przez weryfikację nu...   \n",
       "\n",
       "                       category  \n",
       "0              FAQ; wrong copy;  \n",
       "1  FAQ; content categorization;  \n",
       "2                   app crashes  \n",
       "3                            UX  \n",
       "4                           OTP  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clearing data\n",
    "# remove duplicates\n",
    "input_data.drop_duplicates(inplace=True)\n",
    "# remove empty\n",
    "input_data=input_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [content, category]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find duplicates\n",
    "input_data[input_data.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "załadowanie słowników tłumaczeń"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Słownik synonimów / podmian\n",
    "\n",
    "podmiany=pd.read_excel(os.path.join(datapath,'preproc_dict.xlsx'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing of content text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_texts(raw_texts,replacements):\n",
    "    \"\"\"\n",
    "    texts: np.Series containing strings to be preprocessed\n",
    "    replacements: pairs of what convert to what\n",
    "    return np.Series with corrected texts\n",
    "    \"\"\"\n",
    "    resulttext=raw_texts.str.lower()\n",
    "    for [co,naco,_] in replacements.values:\n",
    "       resulttext=resulttext.str.replace(re.compile(str(co)),str(naco))\n",
    "    return resulttext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_texts=preprocess_texts(input_data['content'],podmiany)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    problem z wyświetlaniem informacji w faq w kat...\n",
       "1    w żadnej z kategorii nie ma sekcji najczęstsze...\n",
       "2    moje konto mój plan szczegóły oferty aplikacja...\n",
       "3    klient zgłsza problem z wyborem numerów przy w...\n",
       "4    klienta nie może p rzejść przez weryfikację nu...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(prep_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep_texts.to_csv(os.path.join(datapath,'texts_for_emb.txt'))\n",
    "# incorrect <- validation set użyty do nauki - trzeba poprawić\n",
    "# prep_texts.to_csv(os.path.join(datapath,'texts_for_emb.txt'),sep='\\n',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_labels(raw_labels):\n",
    "    result_labels=raw_labels.split(';')  # split on ';'\n",
    "    # remove leading space and replace spaces inside to underscore\n",
    "    result_labels=['__' + x.strip().replace(' ','_') + '__' for x in result_labels]\n",
    "    result_string=' '.join(result_labels)\n",
    "    return result_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prep_labels=input_data['category'].apply(preprocess_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prep_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_labels(labels,dictionary=None):\n",
    "    if dictionary==None:\n",
    "        cat_labels, uniques = pd.factorize(labels)\n",
    "    else:\n",
    "        None # dorobić mapowania jeśli słownik już był podany\n",
    "    return cat_labels, uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_labels,label_dict=categorize_labels(prep_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series(cat_labels).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                __FAQ__ __wrong_copy__ ____\n",
       "1    __FAQ__ __content_categorization__ ____\n",
       "2                            __app_crashes__\n",
       "3                                     __UX__\n",
       "4                                    __OTP__\n",
       "Name: category, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_labels.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split data to train and validation parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train,texts_val,y_train,y_val=train_test_split(prep_texts.values,\n",
    "                                                     cat_labels,test_size=0.25,random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save file for fasttext\n",
    "pd.Series(texts_train).to_csv(os.path.join(datapath,'texts_for_emb.txt'),sep='\\n',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampling to boost minority classes\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "\n",
    "texts_train, y_train = ros.fit_resample(np.reshape(texts_train, (-1, 1)),y_train)\n",
    "\n",
    "# shuffle to be sure \n",
    "texts_train, y_train = shuffle(texts_train, y_train, random_state=0)\n",
    "\n",
    "texts_train=texts_train.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare files for fasstext\n",
    "fasttext_train_set=[]\n",
    "for i,t in enumerate(y_train):\n",
    "    fasttext_train_set.append('__label__'+str(t)+' '+texts_train[i])\n",
    "\n",
    "fasttext_val_set=texts_val\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(fasttext_train_set).to_csv(os.path.join(datapath,'fasttext_train_set.txt'),sep='\\n',index=False)\n",
    "pd.Series(fasttext_val_set).to_csv(os.path.join(datapath,'fasttext_val_set.txt'),sep='\\n',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teraz odpalamy fasttext i w wyniku otrzymujemy predictions.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_predicted=pd.read_csv(os.path.join(datapath,'predictions.txt'), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_fasttext_label = lambda x: int(re.sub('__label__','',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_predicted=y_val_predicted.applymap(drop_fasttext_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred=y_val_predicted.values\n",
    "#print(y_val_predicted)\n",
    "print(y_val_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampling also validation set \n",
    "#texts_val, y_val = ros.fit_resample(np.reshape(texts_val, (-1, 1)),y_val)\n",
    "#texts_val=texts_val.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(texts_train.shape)\n",
    "print(y_train.shape)\n",
    "print(texts_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampling to boost minority classes\n",
    "# ros = RandomOverSampler(random_state=0)\n",
    "\n",
    "# x_train, y_train = ros.fit_resample(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create mlp model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate statistics per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_prob = mymodel.predict(x_val) \n",
    "#y_preds = y_prob.argmax(axis=-1)\n",
    "y_preds = y_val_pred\n",
    "cm = metrics.confusion_matrix(y_val, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(list(y_val),list(y_preds),labels=[1,2,3,4],target_names=label_dict[1:]))\n",
    "#print(metrics.classification_report(list(y_val),list(y_preds),target_names=label_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(cm, label_dict, label_dict)\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.set(font_scale=1.0)#for label size\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 12})# font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_val).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mymodel.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_train = mymodel.predict(x_train) \n",
    "y_preds_train = y_prob_train.argmax(axis=-1)\n",
    "cm_train = metrics.confusion_matrix(y_train, y_preds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm_train = pd.DataFrame(cm_train, label_dict, label_dict)\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.set(font_scale=1.0)#for label size\n",
    "sn.heatmap(df_cm_train, annot=True, annot_kws={\"size\": 12})# font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(list(y_train),list(y_preds_train),labels=[1,2,3,4],target_names=label_dict[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_ngram_model(data):\n",
    "    \"\"\"Tunes n-gram model on the given dataset.\n",
    "\n",
    "    # Arguments\n",
    "        data: tuples of training and test texts and labels.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Select parameter values to try.\n",
    "    num_layers = [1, 2, 3]\n",
    "    num_units = [4, 6, 10]\n",
    "    #dropouts =[0.3,0.4,0.5]\n",
    "\n",
    "    # Save parameter combination and results.\n",
    "    params = {\n",
    "        'layers': [],\n",
    "        'units': [],\n",
    "        'accuracy': [],\n",
    "        'loss':[],\n",
    "        'f1':[],\n",
    "    }\n",
    "    \n",
    "    (x_train, y_train), (x_val, y_val) = data\n",
    "\n",
    "    # Iterate over all parameter combinations.\n",
    "    for layers in num_layers:\n",
    "        for units in num_units:\n",
    "                params['layers'].append(layers)\n",
    "                params['units'].append(units)\n",
    "                print(f'parameters: layers-{layers}, units-{units}')\n",
    "                myaccuracy, myloss, mymodel = train_ngram_model(data,\n",
    "                      num_classes=len(label_dict),\n",
    "                      learning_rate=4e-3,\n",
    "                      epochs=7,\n",
    "                      batch_size=128,\n",
    "                      layers=layers,\n",
    "                      units=units,\n",
    "                      dropout_rate=0.4,\n",
    "                      l2=0.005)\n",
    "                y_prob = mymodel.predict(x_val) \n",
    "                y_preds = y_prob.argmax(axis=-1)\n",
    "                myf1=metrics.f1_score(list(y_val),list(y_preds),labels=[1,2,3,4])\n",
    "                print((f'Accuracy: {myaccuracy}, Loss: {myloss}, F1: {myf1}, Parameters: (layers={layers}, units={units})'))\n",
    "                params['accuracy'].append(myaccuracy)\n",
    "                params['loss'].append(myloss)\n",
    "                params['f1'].append(myf1)\n",
    "    #_plot_parameters(params)\n",
    "    return params\n",
    "    \n",
    "def _plot_parameters(params):\n",
    "    \"\"\"Creates a 3D surface plot of given parameters.\n",
    "\n",
    "    # Arguments\n",
    "        params: dict, contains layers, units and accuracy value combinations.\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "    ax.plot_trisurf(params['layers'],\n",
    "                    params['units'],\n",
    "                    params['accuracy'],\n",
    "                    cmap=cm.coolwarm,\n",
    "                    antialiased=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wyniki = tune_ngram_model(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
